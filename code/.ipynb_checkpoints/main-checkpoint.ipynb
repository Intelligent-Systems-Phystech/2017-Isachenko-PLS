{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T21:24:38.506749Z",
     "start_time": "2017-10-23T21:24:38.496980Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T21:12:36.837002Z",
     "start_time": "2017-10-23T21:12:36.818930Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _center_scale_xy(X, Y):\n",
    "    \"\"\" Center X, Y and scale\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        X, Y, x_mean, y_mean, x_std, y_std\n",
    "    \"\"\"\n",
    "    # center\n",
    "    x_mean = X.mean(axis=0)\n",
    "    X -= x_mean\n",
    "    y_mean = Y.mean(axis=0)\n",
    "    Y -= y_mean\n",
    "    # scale\n",
    "    x_std = X.std(axis=0, ddof=1)\n",
    "    x_std[x_std == 0.0] = 1.0\n",
    "    X /= x_std\n",
    "    y_std = Y.std(axis=0, ddof=1)\n",
    "    y_std[y_std == 0.0] = 1.0\n",
    "    Y /= y_std\n",
    "    return X, Y, x_mean, y_mean, x_std, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T21:26:14.512458Z",
     "start_time": "2017-10-23T21:26:14.471392Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nipals(X, Y, max_iter=500, tol=1e-06,\n",
    "                                 norm_y_weights=False):\n",
    "    \"\"\"Inner loop of the iterative NIPALS algorithm.\n",
    "    Provides an alternative to the svd(X'Y); returns the first left and right\n",
    "    singular vectors of X'Y.  See PLS for the meaning of the parameters.  It is\n",
    "    similar to the Power method for determining the eigenvectors and\n",
    "    eigenvalues of a X'Y.\n",
    "    \n",
    "    y_score - U\n",
    "    y_weights - C\n",
    "    x_score - T\n",
    "    x_weights - W\n",
    "    \n",
    "    Return: vectors w, c\n",
    "    \"\"\"\n",
    "    # 1: initialization of u\n",
    "    u = Y[:, [0]]\n",
    "# TEST IT!!!!\n",
    "    t_old = 0\n",
    "    ite = 1\n",
    "    eps = np.finfo(X.dtype).eps\n",
    "    # Inner loop of the Wold algo.\n",
    "    while True:\n",
    "        # w = X^T u / (u^T u)\n",
    "        w = np.dot(X.T, u) / np.dot(u.T, u)\n",
    "        \n",
    "        # If u only has zeros w will only have zeros. In\n",
    "        # this case add an epsilon to converge to a more acceptable\n",
    "        # solution\n",
    "        if np.dot(w.T, w) < eps:\n",
    "            w += eps\n",
    "        # w = w / |w|\n",
    "        w /= (np.sqrt(np.dot(w.T, w)) + eps)\n",
    "        \n",
    "        # t = Xw\n",
    "        t = np.dot(X, w)\n",
    "        \n",
    "        # c = Y^T t / (t^T t)\n",
    "        c = np.dot(Y.T, t) / np.dot(t.T, t)\n",
    "        \n",
    "        # c = c / |c|\n",
    "# ????? (TEST IT!!!)\n",
    "        if norm_y_weights:\n",
    "            c /= np.sqrt(np.dot(c.T, c)) + eps\n",
    "\n",
    "        # u = Yc\n",
    "# ????? (TEST IT!!!!)\n",
    "        u = np.dot(Y, y_weights) / (np.dot(c.T, c) + eps)\n",
    "        \n",
    "        # 10: convergence of t\n",
    "        t_diff = t - t_old\n",
    "        if np.dot(t_diff.T, t_diff) < tol or Y.shape[1] == 1:\n",
    "            break \n",
    "        if ite == max_iter:\n",
    "            warnings.warn('Maximum number of iterations reached')\n",
    "            break\n",
    "        t_old = t\n",
    "        ite += 1\n",
    "    return w, c, ite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import svd_flip\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.utils import check_array, check_consistent_length\n",
    "from sklearn.externals import six\n",
    "\n",
    "import warnings\n",
    "from abc import ABCMeta, abstractmethod\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from sklearn.utils import arpack\n",
    "from sklearn.utils.validation import check_is_fitted, FLOAT_DTYPES\n",
    "\n",
    "pinv2_args = {'check_finite': False}\n",
    "\n",
    "\n",
    "class _PLS(six.with_metaclass(ABCMeta), BaseEstimator, TransformerMixin,\n",
    "           RegressorMixin):\n",
    "    \"\"\"\n",
    "    Partial Least Squares (PLS)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self, n_components=2, deflation_mode=\"regression\",\\\n",
    "                 algorithm=\"nipals\", trans_function_name=None, trans_parameters=None,\\\n",
    "                 norm_y_weights=False, max_iter=500, tol=1e-06, copy=True):\n",
    "        self.n_components = n_components\n",
    "        self.deflation_mode = deflation_mode\n",
    "        self.norm_y_weights = norm_y_weights\n",
    "        self.algorithm = algorithm\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.copy = copy\n",
    "        self.trans_function_name = trans_function_name\n",
    "        self.trans_parameters = trans_parameters\n",
    "        \n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Fit model to data.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # copy since this will contains the residuals (deflated) matrices\n",
    "        check_consistent_length(X, Y)\n",
    "        X = check_array(X, dtype=np.float64, copy=self.copy)\n",
    "        Y = check_array(Y, dtype=np.float64, copy=self.copy, ensure_2d=False)\n",
    "        if Y.ndim == 1:\n",
    "            Y = Y.reshape(-1, 1)\n",
    "\n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        q = Y.shape[1]\n",
    "\n",
    "        if self.n_components < 1 or self.n_components > p:\n",
    "            raise ValueError('Invalid number of components: %d' %\n",
    "                             self.n_components)\n",
    "        if self.algorithm not in nipals\", \"nipals_nonlinear\"):\n",
    "            raise ValueError(\"Got algorithm %s when only 'svd' \"\n",
    "                             \"and 'nipals' are known\" % self.algorithm)\n",
    "        if self.algorithm == \"svd\" and self.mode == \"B\":\n",
    "            raise ValueError('Incompatible configuration: mode B is not '\n",
    "                             'implemented with svd algorithm')\n",
    "        if self.deflation_mode not in [\"canonical\", \"regression\"]:\n",
    "            raise ValueError('The deflation mode is unknown')\n",
    "        # Scale (in place)\n",
    "        X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_ = (\n",
    "            _center_scale_xy(X, Y))\n",
    "        # Residuals (deflated) matrices\n",
    "        Xk = X\n",
    "        Yk = Y\n",
    "        # Results matrices\n",
    "        self.x_scores_ = np.zeros((n, self.n_components))\n",
    "        self.y_scores_ = np.zeros((n, self.n_components))\n",
    "        self.x_weights_ = np.zeros((p, self.n_components))\n",
    "        self.y_weights_ = np.zeros((q, self.n_components))\n",
    "        self.x_loadings_ = np.zeros((p, self.n_components))\n",
    "        self.y_loadings_ = np.zeros((q, self.n_components))\n",
    "        self.n_iter_ = []\n",
    "\n",
    "        trans_parameters = np.ones([Y.shape[0], Y.shape[1]*2])*np.random.randn()\n",
    "#         y_tilde = trans_function(self.trans_function_name, Y, trans_parameters)\n",
    "        \n",
    "        # NIPALS algo: outer loop, over components\n",
    "        for k in range(self.n_components):\n",
    "            if np.all(np.dot(Yk.T, Yk) < np.finfo(np.double).eps):\n",
    "                # Yk constant\n",
    "                warnings.warn('Y residual constant at iteration %s' % k)\n",
    "                break\n",
    "            # 1) weights estimation (inner loop)\n",
    "            # -----------------------------------\n",
    "            if self.algorithm == \"nipals\":\n",
    "                x_weights, y_weights, n_iter_ = \\\n",
    "                    _nipals_twoblocks_inner_loop(\\\n",
    "                             X=Xk, Y=Yk, max_iter=self.max_iter,\\\n",
    "                             tol=self.tol, norm_y_weights=self.norm_y_weights,)\n",
    "                self.n_iter_.append(n_iter_)\n",
    "            if self.algorithm == \"nipals_nonlinear\":\n",
    "                x_weights, y_weights, trans_parameters, y_tilde, n_iter_ = \\\n",
    "                    _nipals_twoblocks_inner_loop_nonlinear(\\\n",
    "                             X=Xk, Y=Yk, max_iter=self.max_iter,\\\n",
    "                             tol=self.tol, norm_y_weights=self.norm_y_weights,\\\n",
    "                             trans_function_name=self.trans_function_name,\\\n",
    "                             trans_parameters=trans_parameters)\n",
    "                self.n_iter_.append(n_iter_)\n",
    "            # Forces sign stability of x_weights and y_weights\n",
    "            # Sign undeterminacy issue from svd if algorithm == \"svd\"\n",
    "            # and from platform dependent computation if algorithm == 'nipals'\n",
    "            x_weights, y_weights = svd_flip(x_weights, y_weights.T)\n",
    "            y_weights = y_weights.T\n",
    "            # compute scores\n",
    "            x_scores = np.dot(Xk, x_weights)\n",
    "            if self.norm_y_weights:\n",
    "                y_ss = 1\n",
    "            else:\n",
    "                y_ss = np.dot(y_weights.T, y_weights) + np.finfo(np.double).eps\n",
    "            if self.algorithm==\"nipals\":\n",
    "                y_scores = np.dot(Yk, y_weights) / y_ss\n",
    "            if self.algorithm==\"nipals_nonlinear\":\n",
    "                y_scores = np.dot(y_tilde, y_weights) / y_ss\n",
    "            \n",
    "            # test for null variance\n",
    "            if np.dot(x_scores.T, x_scores) < np.finfo(np.double).eps:\n",
    "                warnings.warn('X scores are null at iteration %s' % k)\n",
    "                break\n",
    "            # 2) Deflation (in place)\n",
    "            # - regress Xk's on x_score\n",
    "            x_loadings = np.dot(Xk.T, x_scores) / (np.dot(x_scores.T, x_scores) + \\\n",
    "                                                   np.finfo(np.double).eps)\n",
    "            # - subtract rank-one approximations to obtain remainder matrix\n",
    "            Xk -= np.dot(x_scores, x_loadings.T)\n",
    "# TO THINK HOW TO CHANGE TILDE Y\n",
    "            if self.deflation_mode == \"canonical\":\n",
    "                # - regress Yk's on y_score, then subtract rank-one approx.\n",
    "                y_loadings = (np.dot(Yk.T, y_scores)\n",
    "                              / np.dot(y_scores.T, y_scores))\n",
    "                \n",
    "                if self.algorithm==\"nipals\":\n",
    "                    Yk -= np.dot(x_scores, y_loadings.T)\n",
    "                if self.algorithm==\"nipals_nonlinear\":\n",
    "                    y_tilde -= np.dot(y_scores, y_loadings.T)\n",
    "                    Yk = inverse_trans_function(self.trans_function_name, y_tilde, trans_parameters)\n",
    "            if self.deflation_mode == \"regression\":\n",
    "                # - regress Yk's on x_score, then subtract rank-one approx.\n",
    "                y_loadings = (np.dot(Yk.T, x_scores)\n",
    "                              / np.dot(x_scores.T, x_scores))\n",
    "                if self.algorithm==\"nipals_nonlinear\":\n",
    "                    y_tilde -= np.dot(y_scores, y_loadings.T) #регрессия на \\tilde{Y}???\n",
    "                    # COMPUTE Yk AND INVERSE\n",
    "                    Yk = inverse_trans_function(self.trans_function_name, y_tilde, trans_parameters)\n",
    "                if self.algorithm==\"nipals\":\n",
    "                    Yk -= np.dot(x_scores, y_loadings.T)\n",
    "            # 3) Store weights, scores and loadings # Notation:\n",
    "            self.x_scores_[:, k] = x_scores.ravel()  # T\n",
    "            self.y_scores_[:, k] = y_scores.ravel()  # U\n",
    "            self.x_weights_[:, k] = x_weights.ravel()  # W\n",
    "            self.y_weights_[:, k] = y_weights.ravel()  # C\n",
    "            self.x_loadings_[:, k] = x_loadings.ravel()  # P\n",
    "            self.y_loadings_[:, k] = y_loadings.ravel()  # Q\n",
    "        # Such that: X = TP' + Err and Y = UQ' + Err\n",
    "\n",
    "        # 4) rotations from input space to transformed space (scores)\n",
    "        # T = X W(P'W)^-1 = XW* (W* : p x k matrix)\n",
    "        # U = Y C(Q'C)^-1 = YC* (W* : q x k matrix)\n",
    "        self.x_rotations_ = np.dot(\n",
    "            self.x_weights_,\n",
    "            linalg.pinv2(np.dot(self.x_loadings_.T, self.x_weights_),\n",
    "                         **pinv2_args))\n",
    "        if Y.shape[1] > 1:\n",
    "            self.y_rotations_ = np.dot(\n",
    "                self.y_weights_,\n",
    "                linalg.pinv2(np.dot(self.y_loadings_.T, self.y_weights_),\n",
    "                             **pinv2_args))\n",
    "        else:\n",
    "            self.y_rotations_ = np.ones(1)\n",
    "\n",
    "        if True or self.deflation_mode == \"regression\":\n",
    "            # FIXME what's with the if?\n",
    "            # Estimate regression coefficient\n",
    "            # Regress Y on T\n",
    "            # Y = TQ' + Err,\n",
    "            # Then express in function of X\n",
    "            # Y = X W(P'W)^-1Q' + Err = XB + Err\n",
    "            # => B = W*Q' (p x q)\n",
    "            self.coef_ = np.dot(self.x_rotations_, self.y_loadings_.T)\n",
    "            self.coef_ = (1. / self.x_std_.reshape((p, 1)) * self.coef_ *\n",
    "                          self.y_std_)\n",
    "        self.trans_parameters = trans_parameters\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None, copy=True):\n",
    "        \"\"\"Apply the dimension reduction learned on the train data.\n",
    "\n",
    "        x_scores if Y is not given, (x_scores, y_scores) otherwise.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'x_mean_')\n",
    "        X = check_array(X, copy=copy, dtype=FLOAT_DTYPES)\n",
    "        # Normalize\n",
    "        X -= self.x_mean_\n",
    "        X /= self.x_std_\n",
    "        # Apply rotation\n",
    "        x_scores = np.dot(X, self.x_rotations_)\n",
    "        if Y is not None:\n",
    "            Y = check_array(Y, ensure_2d=False, copy=copy, dtype=FLOAT_DTYPES)\n",
    "            if Y.ndim == 1:\n",
    "                Y = Y.reshape(-1, 1)\n",
    "# G?\n",
    "            Y -= self.y_mean_\n",
    "            Y /= self.y_std_\n",
    "# MB TILDE Y\n",
    "            y_scores = np.dot(Y, self.y_rotations_)\n",
    "            return x_scores, y_scores\n",
    "\n",
    "        return x_scores\n",
    "\n",
    "    def predict(self, X, copy=True):\n",
    "        \"\"\"Apply the dimension reduction learned on the train data.\n",
    "        \n",
    "        This call requires the estimation of a p x q matrix, which may\n",
    "        be an issue in high dimensional space.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'x_mean_')\n",
    "        X = check_array(X, copy=copy, dtype=FLOAT_DTYPES)\n",
    "        # Normalize\n",
    "        X -= self.x_mean_\n",
    "        X /= self.x_std_\n",
    "        Ypred = np.dot(X, self.coef_)\n",
    "        return Ypred + self.y_mean_\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        \"\"\"\n",
    "        Learn and apply the dimension reduction on the train data.\n",
    "\n",
    "        x_scores if Y is not given, (x_scores, y_scores) otherwise.\n",
    "        \"\"\"\n",
    "        return self.fit(X, y, **fit_params).transform(X, y)\n",
    "\n",
    "\n",
    "class PLSRegression(_PLS):\n",
    "    \"\"\"\n",
    "    PLS regression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components=2,max_iter=500, tol=1e-06, copy=True, trans_function_name=None):\n",
    "        super(PLSRegression, self).__init__(\n",
    "            n_components=n_components,\n",
    "            deflation_mode=\"regression\", trans_function_name=trans_function_name,\n",
    "            norm_y_weights=False, max_iter=max_iter, tol=tol, copy=copy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
